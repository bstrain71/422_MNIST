{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Strain Assignment 6.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "rX8mhOLljYeM"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bstrain71/422_MNIST/blob/master/Strain_Assignment_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0trJmd6DjqBZ",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "# Install TensorFlow\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnEH2YO2Ffeq",
        "colab_type": "text"
      },
      "source": [
        "## Ingest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIIgiK9z1zY2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7FP5258xjs-v",
        "colab": {}
      },
      "source": [
        "# load the kaggle csvs from my own drive\n",
        "import pandas as pd\n",
        "test_df = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/MNIST/test.csv')\n",
        "train_df = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/MNIST/train.csv')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBmS8CbY2GzF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_df.shape) # 42000x785? OK\n",
        "print(test_df.shape) # 28000x784? OK"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLrB25c82Kxo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split train.csv in to xtrain ytrain\n",
        "x_train = train_df.drop(columns=['label'])\n",
        "y_train = train_df['label']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x_train, y_train, test_size=0.33, random_state=24601)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQk6AymH28Nv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtcPH9XG3fSi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# the shapes are correct so make them into numpy arrays for tf to use\n",
        "x_train = np.asarray(x_train)\n",
        "y_train = np.asarray(y_train)\n",
        "x_test = np.asarray(x_test)\n",
        "y_test = np.asarray(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0Nh71EoFmJF",
        "colab_type": "text"
      },
      "source": [
        "## EDA (N\\A) for MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BPZ68wASog_I"
      },
      "source": [
        "## Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h3IKyzTCDNGo",
        "colab": {}
      },
      "source": [
        "# Build 5 Models\n",
        "\n",
        "# 5 hidden layers 128 nodes per layer\n",
        "model1 = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(784),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model1.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 4 layers 160 nodes per layer\n",
        "model2 = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(784),\n",
        "  tf.keras.layers.Dense(160, activation='relu'),\n",
        "  tf.keras.layers.Dense(160, activation='relu'),\n",
        "  tf.keras.layers.Dense(160, activation='relu'),\n",
        "  tf.keras.layers.Dense(160, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model2.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 10 layers 64 nodes per layer\n",
        "model3 = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(784),\n",
        "  tf.keras.layers.Dense(64, activation='relu'),\n",
        "  tf.keras.layers.Dense(64, activation='relu'),\n",
        "  tf.keras.layers.Dense(64, activation='relu'),\n",
        "  tf.keras.layers.Dense(64, activation='relu'),\n",
        "  tf.keras.layers.Dense(64, activation='relu'),\n",
        "  tf.keras.layers.Dense(64, activation='relu'),\n",
        "  tf.keras.layers.Dense(64, activation='relu'),\n",
        "  tf.keras.layers.Dense(64, activation='relu'),\n",
        "  tf.keras.layers.Dense(64, activation='relu'),\n",
        "  tf.keras.layers.Dense(64, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model3.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 20 layers 32 nodes per layer\n",
        "model4 = tf.keras.models.Sequential([\n",
        "  #tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(32, activation='relu'),\n",
        "  tf.keras.layers.Dense(32, activation='relu'),\n",
        "  tf.keras.layers.Dense(32, activation='relu'),\n",
        "  tf.keras.layers.Dense(32, activation='relu'),\n",
        "  tf.keras.layers.Dense(32, activation='relu'),\n",
        "  tf.keras.layers.Dense(32, activation='relu'),\n",
        "  tf.keras.layers.Dense(32, activation='relu'),\n",
        "  tf.keras.layers.Dense(32, activation='relu'),\n",
        "  tf.keras.layers.Dense(32, activation='relu'),\n",
        "  tf.keras.layers.Dense(32, activation='relu'),\n",
        "  tf.keras.layers.Dense(32, activation='relu'),\n",
        "  tf.keras.layers.Dense(32, activation='relu'),\n",
        "  tf.keras.layers.Dense(32, activation='relu'),\n",
        "  tf.keras.layers.Dense(32, activation='relu'),\n",
        "  tf.keras.layers.Dense(32, activation='relu'),\n",
        "  tf.keras.layers.Dense(32, activation='relu'),\n",
        "  tf.keras.layers.Dense(32, activation='relu'),\n",
        "  tf.keras.layers.Dense(32, activation='relu'),\n",
        "  tf.keras.layers.Dense(32, activation='relu'),\n",
        "  tf.keras.layers.Dense(32, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model4.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 40 layers 16 nodes per layer\n",
        "model5 = tf.keras.models.Sequential([\n",
        "  #tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(16, activation='relu'),\n",
        "  tf.keras.layers.Dense(16, activation='relu'),\n",
        "  tf.keras.layers.Dense(16, activation='relu'),\n",
        "  tf.keras.layers.Dense(16, activation='relu'),\n",
        "  tf.keras.layers.Dense(16, activation='relu'),\n",
        "  tf.keras.layers.Dense(16, activation='relu'),\n",
        "  tf.keras.layers.Dense(16, activation='relu'),\n",
        "  tf.keras.layers.Dense(16, activation='relu'),\n",
        "  tf.keras.layers.Dense(16, activation='relu'),\n",
        "  tf.keras.layers.Dense(16, activation='relu'),\n",
        "  tf.keras.layers.Dense(16, activation='relu'),\n",
        "  tf.keras.layers.Dense(16, activation='relu'),\n",
        "  tf.keras.layers.Dense(16, activation='relu'),\n",
        "  tf.keras.layers.Dense(16, activation='relu'),\n",
        "  tf.keras.layers.Dense(16, activation='relu'),\n",
        "  tf.keras.layers.Dense(16, activation='relu'),\n",
        "  tf.keras.layers.Dense(16, activation='relu'),\n",
        "  tf.keras.layers.Dense(16, activation='relu'),\n",
        "  tf.keras.layers.Dense(16, activation='relu'),\n",
        "  tf.keras.layers.Dense(16, activation='relu'),\n",
        "  tf.keras.layers.Dense(16, activation='relu'),\n",
        "  tf.keras.layers.Dense(16, activation='relu'),\n",
        "  tf.keras.layers.Dense(16, activation='relu'),\n",
        "  tf.keras.layers.Dense(16, activation='relu'),\n",
        "  tf.keras.layers.Dense(16, activation='relu'),\n",
        "  tf.keras.layers.Dense(16, activation='relu'),\n",
        "  tf.keras.layers.Dense(16, activation='relu'),\n",
        "  tf.keras.layers.Dense(16, activation='relu'),\n",
        "  tf.keras.layers.Dense(16, activation='relu'),\n",
        "  tf.keras.layers.Dense(16, activation='relu'),\n",
        "  tf.keras.layers.Dense(16, activation='relu'),\n",
        "  tf.keras.layers.Dense(16, activation='relu'),\n",
        "  tf.keras.layers.Dense(16, activation='relu'),\n",
        "  tf.keras.layers.Dense(16, activation='relu'),\n",
        "  tf.keras.layers.Dense(16, activation='relu'),\n",
        "  tf.keras.layers.Dense(16, activation='relu'),\n",
        "  tf.keras.layers.Dense(16, activation='relu'),\n",
        "  tf.keras.layers.Dense(16, activation='relu'),\n",
        "  tf.keras.layers.Dense(16, activation='relu'),\n",
        "  tf.keras.layers.Dense(16, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model5.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ix4mEL65on-w"
      },
      "source": [
        "Train and evaluate the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "F7dTAzgHDUh7",
        "colab": {}
      },
      "source": [
        "# model1\n",
        "from datetime import datetime\n",
        "start=datetime.now()\n",
        "model1.fit(x_train, y_train, epochs=10)\n",
        "model1.evaluate(x_test,  y_test, verbose=2)\n",
        "end=datetime.now()\n",
        "print(end-start)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hnu8KnIhhL0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model2\n",
        "start=datetime.now()\n",
        "model2.fit(x_train, y_train, epochs=10)\n",
        "model2.evaluate(x_test,  y_test, verbose=2)\n",
        "end=datetime.now()\n",
        "print(end-start)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bg-Jqge1hkoD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model 3\n",
        "start=datetime.now()\n",
        "model3.fit(x_train, y_train, epochs=10)\n",
        "model3.evaluate(x_test,  y_test, verbose=2)\n",
        "end=datetime.now()\n",
        "print(end-start)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8Y8O2zbhmok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model 4\n",
        "start=datetime.now()\n",
        "model4.fit(x_train, y_train, epochs=10)\n",
        "model4.evaluate(x_test,  y_test, verbose=2)\n",
        "end=datetime.now()\n",
        "print(end-start)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJJfFq4zhnex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model 5\n",
        "start=datetime.now()\n",
        "model5.fit(x_train, y_train, epochs=10)\n",
        "model5.evaluate(x_test,  y_test, verbose=2)\n",
        "end=datetime.now()\n",
        "print(end-start)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fw5VjP2h6Ote",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get the test dataset\n",
        "x_test = np.asarray(test_df)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFHnalgUmTV3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# put predictions into the right format for kaggle\n",
        "tf_predictions1 = model1.predict(x_test)\n",
        "tf_predictions2 = model2.predict(x_test)\n",
        "tf_predictions3 = model3.predict(x_test)\n",
        "tf_predictions4 = model4.predict(x_test)\n",
        "tf_predictions5 = model5.predict(x_test)\n",
        "\n",
        "\n",
        "print(tf_predictions1.shape)\n",
        "print(tf_predictions2.shape)\n",
        "print(tf_predictions3.shape)\n",
        "print(tf_predictions4.shape)\n",
        "print(tf_predictions5.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dstp-ZbUBstd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get the predicted value based on it's index\n",
        "my_predictions1 = []\n",
        "for i in range(tf_predictions1.shape[0]):    \n",
        "    my_predictions1.append(np.argmax(tf_predictions1[i]))\n",
        "\n",
        "my_predictions2 = []\n",
        "for i in range(tf_predictions2.shape[0]):    \n",
        "    my_predictions2.append(np.argmax(tf_predictions2[i]))\n",
        "\n",
        "my_predictions3 = []\n",
        "for i in range(tf_predictions3.shape[0]):    \n",
        "    my_predictions3.append(np.argmax(tf_predictions3[i]))\n",
        "\n",
        "my_predictions4 = []\n",
        "for i in range(tf_predictions4.shape[0]):    \n",
        "    my_predictions4.append(np.argmax(tf_predictions4[i]))\n",
        "\n",
        "my_predictions5 = []\n",
        "for i in range(tf_predictions5.shape[0]):    \n",
        "    my_predictions5.append(np.argmax(tf_predictions5[i]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Vf2miFfELcn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(my_predictions1))\n",
        "print(len(my_predictions2))\n",
        "print(len(my_predictions3))\n",
        "print(len(my_predictions4))\n",
        "print(len(my_predictions5))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZWdLhpKEqdS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_predictions1 = pd.DataFrame(my_predictions1)\n",
        "final_predictions1['ImageId'] = test_df.index + 1\n",
        "final_predictions1 = final_predictions1.rename(columns={0:\"Label\"})\n",
        "final_predictions1 = final_predictions1.reindex(columns=['ImageId','Label'])\n",
        "\n",
        "final_predictions2 = pd.DataFrame(my_predictions2)\n",
        "final_predictions2['ImageId'] = test_df.index + 1\n",
        "final_predictions2 = final_predictions2.rename(columns={0:\"Label\"})\n",
        "final_predictions2 = final_predictions2.reindex(columns=['ImageId','Label'])\n",
        "\n",
        "final_predictions3 = pd.DataFrame(my_predictions3)\n",
        "final_predictions3['ImageId'] = test_df.index + 1\n",
        "final_predictions3 = final_predictions3.rename(columns={0:\"Label\"})\n",
        "final_predictions3 = final_predictions3.reindex(columns=['ImageId','Label'])\n",
        "\n",
        "final_predictions4 = pd.DataFrame(my_predictions4)\n",
        "final_predictions4['ImageId'] = test_df.index + 1\n",
        "final_predictions4 = final_predictions4.rename(columns={0:\"Label\"})\n",
        "final_predictions4 = final_predictions4.reindex(columns=['ImageId','Label'])\n",
        "\n",
        "final_predictions5 = pd.DataFrame(my_predictions5)\n",
        "final_predictions5['ImageId'] = test_df.index + 1\n",
        "final_predictions5 = final_predictions5.rename(columns={0:\"Label\"})\n",
        "final_predictions5 = final_predictions5.reindex(columns=['ImageId','Label'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9t4AnQFm9p_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(final_predictions1.shape)\n",
        "print(final_predictions2.shape)\n",
        "print(final_predictions3.shape)\n",
        "print(final_predictions4.shape)\n",
        "print(final_predictions5.shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4MOzfeDFsyt",
        "colab_type": "text"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "Kaggle Submission Scores:\n",
        "\n",
        "Model 1: 0.93571\n",
        "\n",
        "Model 2: 0.93928\n",
        "\n",
        "Model 3: 0.95171\n",
        "\n",
        "Model 4: 0.92985\n",
        "\n",
        "Model 5: 0.55585"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIPkIiFLlEG9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# export to csv\n",
        "export_csv = final_predictions1.to_csv (r'/content/gdrive/My Drive/Colab Notebooks/MNIST/tf_results1.csv',\n",
        "                        index = None,\n",
        "                        header=True)\n",
        "\n",
        "export_csv = final_predictions2.to_csv (r'/content/gdrive/My Drive/Colab Notebooks/MNIST/tf_results2.csv',\n",
        "                        index = None,\n",
        "                        header=True)\n",
        "\n",
        "export_csv = final_predictions3.to_csv (r'/content/gdrive/My Drive/Colab Notebooks/MNIST/tf_results3.csv',\n",
        "                        index = None,\n",
        "                        header=True)\n",
        "\n",
        "export_csv = final_predictions4.to_csv (r'/content/gdrive/My Drive/Colab Notebooks/MNIST/tf_results4.csv',\n",
        "                        index = None,\n",
        "                        header=True)\n",
        "\n",
        "export_csv = final_predictions5.to_csv (r'/content/gdrive/My Drive/Colab Notebooks/MNIST/tf_results5.csv',\n",
        "                        index = None,\n",
        "                        header=True)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}